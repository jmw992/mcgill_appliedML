{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 Real Life Data Set\n",
    "    by Jacob Williams\n",
    "    id 260400597\n",
    "    email jacob.williams@mail.mcgill.ca\n",
    "    for Applied Machine Learning - COMP 552\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#command to turn on autocomplete in jupyter to make my life easier\n",
    "%config IPCompleter.greedy=True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.  Cleaning Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 124)\n",
      "(124,)\n",
      "(1994, 124)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "import pylab\n",
    "from numpy.linalg import inv\n",
    "\n",
    "TrnDf = pd.read_csv('Data\\Q3data\\q3data_all.csv', index_col=False)\n",
    "\n",
    "\n",
    "#print(TrnDf)\n",
    "#TrnDf.apply(pd.to_numeric)\n",
    "\n",
    "#categorical variables a little lazy and not developing their own binary dimensions\n",
    "TrnDf.pop('state')\n",
    "TrnDf.pop('county')\n",
    "TrnDf.pop('community')\n",
    "TrnDf.pop('communityname')\n",
    "\n",
    "\n",
    "\n",
    "def isnumber(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "'''\n",
    "This function will take a \n",
    "'''\n",
    "def cleanData(df):\n",
    "    #\n",
    "    df = df[df.applymap(isnumber)]\n",
    "    df = df.replace(to_replace=False , value=np.nan)\n",
    "    \n",
    "    # handles int or string version of numbers\n",
    "    df= df.astype(dtype='float64')\n",
    "\n",
    "\n",
    "    clmMns = df.mean(axis=0)\n",
    "    clmStd = df.std(axis=0)\n",
    "\n",
    "    print(df.shape)\n",
    "\n",
    "    print(clmMns.shape)\n",
    "\n",
    "    numrows = df.shape[0]\n",
    "    \n",
    "    lostLbls = []\n",
    "    \n",
    "    #clmLbls = list(clmMeans.axes.values)\n",
    "    #print(clmLbls)\n",
    "    for clm in df:\n",
    "        if clm in clmMns:\n",
    "            avg = clmMns.loc[clm]\n",
    "            std = clmStd.loc[clm]\n",
    "            for row in range(numrows):\n",
    "                isnan = df.loc[row,clm]\n",
    "                #nan!=nan returns true in python\n",
    "                if (isnan!=isnan):\n",
    "                    df.at[row,clm]=np.random.normal(avg,std)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TrnDf = cleanData(TrnDf)\n",
    "TrnDf.to_csv('Data\\Q3data\\q3cleaned.csv', index=False)\n",
    "print(TrnDf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Fitting With Crossover Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preparing K-Folds files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function largely helped by stack overflow below\n",
    "#https://stackoverflow.com/questions/21333832/how-to-save-pandas-groups-to-separate-files\n",
    "'''\n",
    "def groupSplitDf(df, grpClm, exprtPath):\n",
    "    #we have 10 folds listed in the data file and are requested to do 80-20 split,\n",
    "    # so we must split the files into 5 folds\n",
    "    grouped = df.groupby([grpClm])\n",
    "    \n",
    "    for grpItem, group in grouped:\n",
    "        if(grpItem%2==1):\n",
    "            fldNum = int(grpItem/2)+1\n",
    "            exprtFile =  exprtPath+str(fldNum)+'.csv'\n",
    "            cmbndDf = group\n",
    "        else:\n",
    "            cmbndDf = pd.concat([cmbndDf, group])\n",
    "            cmbndDf.to_csv(exprtFile, index=False)\n",
    "        \n",
    "\n",
    "'''\n",
    "This function will read through seperated fold files and will seperate out\n",
    "the specified fold number into test X and Y numpy matrices.  \n",
    "It will agglomerate the rest of the folds together into a training X & Y numpy\n",
    "matrix.  The Y column must be the last column in the data to function properly\n",
    "and the fold number must be specified as last characters in the file names.\n",
    "'''\n",
    "def cvldTrnMkr(fldClm, numFld, tstFld, genericFile):\n",
    "    fldFile = genericFile + str(tstFld) +'.csv'\n",
    "    \n",
    "    trnDf = pd.read_csv(fldFile, index_col=False)\n",
    "    dfEmpty = True\n",
    "    \n",
    "    for fld in range(1,numFld+1,1):\n",
    "        fldFile = genericFile + str(fld) +'.csv'\n",
    "        if (dfEmpty and fld != tstFld ):\n",
    "            dfEmpty = False\n",
    "            trnDf = pd.read_csv(fldFile, index_col=False)\n",
    "        \n",
    "        elif(fld!=tstFld):\n",
    "            trnDf = pd.concat([trnDf, pd.read_csv(fldFile, index_col=False)])\n",
    "\n",
    "    trnDf.pop(fldClm)\n",
    "    trnDf = trnDf.as_matrix()\n",
    " \n",
    "    Xtrn = trnDf[:,0:-1]\n",
    "    Ytrn = trnDf[:,-1]\n",
    "    \n",
    "    return Xtrn, Ytrn\n",
    "\n",
    "def cvldTstMkr(fldClm, numFld, tstFld, genericFile):\n",
    "    fldFile = genericFile + str(tstFld) +'.csv'\n",
    "    tstDf = pd.read_csv(fldFile, index_col=False)\n",
    "    tstDf.pop(fldClm)\n",
    "    tstDf = tstDf.as_matrix()\n",
    "\n",
    "    Xtst = tstDf[:,0:-1]\n",
    "    Ytst = tstDf[:,-1]\n",
    "    return  Xtst, Ytst\n",
    "\n",
    "def getFileHeader(file):\n",
    "    tmpDf = pd.read_csv(file,index_col=None,nrows=1)\n",
    "    tmpDf.pop('fold')\n",
    "    tmpDf.pop('ViolentCrimesPerPop')\n",
    "    hdr = list(tmpDf.columns.values)\n",
    "    hdr = ['ConstantTerm']+hdr\n",
    "    return hdr\n",
    "    \n",
    "        \n",
    "foldFlsPth = 'Data\\Q3data\\q3fold_'\n",
    "groupSplitDf(TrnDf, 'fold', foldFlsPth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#equation to calculate MSE error\n",
    "def errMSE(X, Y, W):\n",
    "    prt1 = np.subtract(Y, np.dot(X,W))\n",
    "    return np.dot(prt1.transpose(),prt1)\n",
    "\n",
    "#modified from Q1 and Q2 to be able to handle input X with multiple\n",
    "# features, adds 1 column for constant term\n",
    "def nDegExpansion(X, n):\n",
    "    #n = n #adding 1 for the constant variables\n",
    "    numrows = X.shape[0]\n",
    "    numclms = X.shape[1]\n",
    "    X_m = np.zeros((numrows, numclms+1)) #add 1 for constant term\n",
    "    cnstnt = np.ones(numrows)\n",
    "    X_m[:,0]=cnstnt\n",
    "    \n",
    "    for r in range(numrows):\n",
    "        for c in range(0,numclms):\n",
    "            for i in range(1,n+1): #add 1 for constant term\n",
    "                #print(c*n+i)\n",
    "                X_m[r,c*n+i] = X[r,c]**i\n",
    "\n",
    "    return X_m\n",
    "\n",
    "#l is a numpy matrix, n is the number of batches in each matrix\n",
    "def batchify(l, n):\n",
    "    #function to create even sized batches of size n\n",
    "    batchLst = []\n",
    "    for i in range(0, len(l), n):\n",
    "        batchLst.append(l[i:i + n,])\n",
    "    return batchLst\n",
    "\n",
    "      \n",
    "def shuffleXY(X, Y):\n",
    "    Y.reshape((len(X),1))\n",
    "\n",
    "    XY = np.column_stack((X,Y))  #concatenate for 1d arrays\n",
    "    np.random.shuffle(XY) #shuffl combined array\n",
    "    Ys = XY[:,-1]\n",
    "    Xs = XY[:,0:-1]\n",
    "    return Xs, Ys\n",
    "\n",
    "#equation to calculate MSE error\n",
    "def errMSE(X, Y, W):\n",
    "    prt1 = np.subtract(Y, np.dot(X,W))\n",
    "    return np.dot(prt1.transpose(),prt1)\n",
    "\n",
    "#takes input x, y, and empty weight matrix and fills in the W matrix\n",
    "#also prints out the predicted Y and W to csv files\n",
    "def fitModel(X, Y):\n",
    "    prt1 = inv(np.dot(X.transpose(), X))\n",
    "    prt2 = np.dot(prt1, X.transpose())\n",
    "    W = np.dot(prt2, Y)\n",
    "    return W\n",
    "    \n",
    "'''\n",
    "function will take X, Y matrix to be fit, the step size aka learning rate,\n",
    "the size of the batches, and the number of iterations to do sgd trainig.\n",
    "Function also shuffles the input and data \n",
    "''' \n",
    "def sgdStepCalc(X, Y, W, stepSize):\n",
    "    # dw = 2*(X.transpose*X*W-X.trans*Y)\n",
    "    #Wi+1 = wi - alpha*dwi\n",
    "    prt1 = np.dot(X.transpose(),X)\n",
    "    prt1 = np.dot(prt1, W)\n",
    "\n",
    "    prt2 = np.dot(X.transpose(),Y)\n",
    "    \n",
    "    dW = np.multiply(2, np.subtract(prt1, prt2))\n",
    "    #print(dW)\n",
    "\n",
    "    return np.subtract(W,  np.multiply(stepSize,dW))\n",
    "\n",
    "'''\n",
    "function will take X, Y matrix and fit them using Stochastic Gradient Descent\n",
    "stepSize : Learning rate, amount to update W matrix at each step\n",
    "btchSize : Number of data points in the learning update batches\n",
    "itrtns : Number of times to loop through all of the data\n",
    "# Number of Epochs = itrts*numRows in training data / batchsize\n",
    "''' \n",
    "def sgdTrain(X, Y, stepSize, btchSize, itrtns):\n",
    "    numRows = X.shape[0]\n",
    "    numClms = X.shape[1]\n",
    "    W = np.zeros((numClms,))\n",
    "    trnMSE = []\n",
    "    epoch = 0\n",
    "    \n",
    "    for i in range(itrtns):\n",
    "        Xbatch, Ybatch = shuffleXY(X, Y)\n",
    "        Xbatch = batchify(Xbatch, btchSize)\n",
    "        Ybatch = batchify(Ybatch, btchSize)\n",
    "        \n",
    "        for j in range(len(Xbatch)):\n",
    "            epoch+=1\n",
    "            W = sgdStepCalc(Xbatch[j], Ybatch[j], W, stepSize)\n",
    "            trnMSE.append(errMSE(X, Y, W))\n",
    "            \n",
    "#     #Graphing info used in debugging       \n",
    "#     plt.title('Online Learning SGD Step 0.05 Training and Valid MSE') \n",
    "#     plt.xlabel('Epoch Number')\n",
    "#     plt.ylabel('MSE')\n",
    "#     plt.plot(range(epoch), trnMSE, 'b')\n",
    "\n",
    "#     #creating legend\n",
    "#     blue_patch = mpatches.Patch(color='blue', label = 'Train MSE')\n",
    "#     plt.legend(handles=[blue_patch])\n",
    "    \n",
    "#     #plt.show()\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Over Fitting Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0\n",
      "Training  1\n",
      "Training  2\n",
      "Training  3\n",
      "Training  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.3496867842102329"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crossOverFit(fldClm, numFld, genericFile, n, stepSize, its, batchSize):\n",
    "    wLst =[]\n",
    "    mse = np.zeros(numFld)\n",
    "    \n",
    "    for fld in range(0,numFld):\n",
    "        Xtrn, Ytrn  = cvldTrnMkr(fldClm, numFld, fld+1, genericFile)\n",
    "        Xtst, Ytst = cvldTstMkr(fldClm, numFld, fld+1, genericFile)\n",
    "\n",
    "        X_m_trn = nDegExpansion(Xtrn, n)\n",
    "        X_m_tst = nDegExpansion(Xtst, n)        \n",
    "\n",
    "        print(\"Training \", fld)\n",
    "\n",
    "        #Wtrn = sgdTrain(X_m_trn,Ytrn,stepSize, batchSize,iterations)\n",
    "        Wtrn = fitModel(X_m_trn, Ytrn, )\n",
    "        mse[fld] = errMSE(X_m_tst, Ytst, Wtrn)\n",
    "        \n",
    "        wLst.append(Wtrn)\n",
    "    \n",
    "    fldFile = genericFile + str(fld) +'.csv'\n",
    "    hdrs = getFileHeader(fldFile)\n",
    "    \n",
    "    numClms = wLst[0].shape[0]\n",
    "    numRows = len(wLst)\n",
    "    wMtrx = np.zeros((numRows, numClms))\n",
    "    for i in range(numRows):\n",
    "        wMtrx[i,:]=wLst[i]\n",
    "        \n",
    "    \n",
    "    fldFile = genericFile + 'ClmWeights.csv'\n",
    "    cmbndDf = pd.DataFrame(data=wMtrx, columns=hdrs)\n",
    "    cmbndDf.to_csv(fldFile, index=False)\n",
    "        \n",
    "        \n",
    "    return np.mean(mse)\n",
    "\n",
    "stepSize = 5e-6\n",
    "iterations = 60\n",
    "batchSize = 20\n",
    "\n",
    "crossOverFit('fold', 5, foldFlsPth, 1, stepSize, iterations, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3  Ridge Regression and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lamda Value 0\n",
      "Training Lamda Value 1\n",
      "Training Lamda Value 2\n",
      "Training Lamda Value 3\n",
      "Training Lamda Value 4\n",
      "Training Lamda Value 5\n",
      "Training Lamda Value 6\n",
      "Training Lamda Value 7\n",
      "Training Lamda Value 8\n",
      "Training Lamda Value 9\n",
      "Training Lamda Value 10\n",
      "Training Lamda Value 11\n",
      "Training Lamda Value 12\n",
      "Training Lamda Value 13\n",
      "Training Lamda Value 14\n",
      "Training Lamda Value 15\n",
      "Training Lamda Value 16\n",
      "Training Lamda Value 17\n",
      "Training Lamda Value 18\n",
      "Training Lamda Value 19\n",
      "Training Lamda Value 20\n",
      "Training Lamda Value 21\n",
      "Training Lamda Value 22\n",
      "Training Lamda Value 23\n",
      "Training Lamda Value 24\n",
      "Training Lamda Value 25\n",
      "Training Lamda Value 26\n",
      "Training Lamda Value 27\n",
      "Training Lamda Value 28\n",
      "Training Lamda Value 29\n",
      "Training Lamda Value 30\n",
      "Training Lamda Value 31\n",
      "Training Lamda Value 32\n",
      "Training Lamda Value 33\n",
      "Training Lamda Value 34\n",
      "Training Lamda Value 35\n",
      "Training Lamda Value 36\n",
      "Training Lamda Value 37\n",
      "Training Lamda Value 38\n",
      "Training Lamda Value 39\n",
      "Training Lamda Value 40\n",
      "Training Lamda Value 41\n",
      "Training Lamda Value 42\n",
      "Training Lamda Value 43\n",
      "Training Lamda Value 44\n",
      "Training Lamda Value 45\n",
      "Training Lamda Value 46\n",
      "Training Lamda Value 47\n",
      "Training Lamda Value 48\n",
      "Training Lamda Value 49\n",
      "Training Lamda Value 50\n",
      "Training Lamda Value 51\n",
      "Training Lamda Value 52\n",
      "Training Lamda Value 53\n",
      "Training Lamda Value 54\n",
      "Training Lamda Value 55\n",
      "Training Lamda Value 56\n",
      "Training Lamda Value 57\n",
      "Training Lamda Value 58\n",
      "Training Lamda Value 59\n",
      "Training Lamda Value 60\n",
      "Training Lamda Value 61\n",
      "Training Lamda Value 62\n",
      "Training Lamda Value 63\n",
      "Training Lamda Value 64\n",
      "Training Lamda Value 65\n",
      "Training Lamda Value 66\n",
      "Training Lamda Value 67\n",
      "Training Lamda Value 68\n",
      "Training Lamda Value 69\n",
      "Training Lamda Value 70\n",
      "Training Lamda Value 71\n",
      "Training Lamda Value 72\n",
      "Training Lamda Value 73\n",
      "Training Lamda Value 74\n",
      "Training Lamda Value 75\n",
      "Training Lamda Value 76\n",
      "Training Lamda Value 77\n",
      "Training Lamda Value 78\n",
      "Training Lamda Value 79\n",
      "Training Lamda Value 80\n",
      "Training Lamda Value 81\n",
      "Training Lamda Value 82\n",
      "Training Lamda Value 83\n",
      "Training Lamda Value 84\n",
      "Training Lamda Value 85\n",
      "Training Lamda Value 86\n",
      "Training Lamda Value 87\n",
      "Training Lamda Value 88\n",
      "Training Lamda Value 89\n",
      "Training Lamda Value 90\n",
      "Training Lamda Value 91\n",
      "Training Lamda Value 92\n",
      "Training Lamda Value 93\n",
      "Training Lamda Value 94\n",
      "Training Lamda Value 95\n",
      "Training Lamda Value 96\n",
      "Training Lamda Value 97\n",
      "Training Lamda Value 98\n",
      "Training Lamda Value 99\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqOL4CFkWqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2988042bb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "function will take X, Y matrix to be fit, the step size aka learning rate,\n",
    "the size of the batches, and the number of iterations to do sgd trainig.\n",
    "Function also shuffles the input and data \n",
    "''' \n",
    "def sgdStepCalcRidge(X, Y, W, stepSize, lmda):\n",
    "    # dw = -2*Xt*(Y-X*w)-2*lmda*w\n",
    "    #Wi+1 = wi - alpha*dwi\n",
    "    prt1 = np.multiply(-2,X.transpose())\n",
    "    prt2 = np.subtract(Y, np.dot(X,W))\n",
    "    prt3 = np.dot(prt1, prt2)\n",
    "    prt4 = np.multiply(2*lmda, W)\n",
    "    \n",
    "    dW = np.subtract(prt3, prt4)\n",
    "\n",
    "    return np.subtract(W,  np.multiply(stepSize,dW))\n",
    "\n",
    "'''\n",
    "function will take X, Y matrix and fit them using Stochastic Gradient Descent\n",
    "stepSize : Learning rate, amount to update W matrix at each step\n",
    "btchSize : Number of data points in the learning update batches\n",
    "itrtns : Number of times to loop through all of the data\n",
    "''' \n",
    "def sgdTrainRidge(X, Y, stepSize, btchSize, itrtns, lmda):\n",
    "    numRows = X.shape[0]\n",
    "    numClms = X.shape[1]\n",
    "    W = np.zeros((numClms,))\n",
    "    trnMSE = []\n",
    "    epoch = 0\n",
    "    \n",
    "    for i in range(itrtns):\n",
    "        Xbatch, Ybatch = shuffleXY(X, Y)\n",
    "        Xbatch = batchify(Xbatch, btchSize)\n",
    "        Ybatch = batchify(Ybatch, btchSize)\n",
    "        \n",
    "        for j in range(len(Xbatch)):\n",
    "            epoch+=1\n",
    "            W = sgdStepCalcRidge(Xbatch[j], Ybatch[j], W, stepSize, lmda)\n",
    "            trnMSE.append(errMSE(X, Y, W))\n",
    "            \n",
    "#     #graphing info used for debugging \n",
    "#     plt.title('Online Learning SGD Step 0.05 Training and Valid MSE') \n",
    "#     plt.xlabel('Epoch Number')\n",
    "#     plt.ylabel('MSE')\n",
    "#     plt.plot(range(epoch), trnMSE, 'b')\n",
    "\n",
    "#     #creating legend\n",
    "#     blue_patch = mpatches.Patch(color='blue', label = 'Train MSE')\n",
    "#     plt.legend(handles=[blue_patch])\n",
    "    \n",
    "#     #plt.show()\n",
    "    \n",
    "    return W\n",
    "\n",
    "def crossOverFitRidge(fldClm, numFld, genericFile, n, stepSize, its, batchSize, lmda):\n",
    "    wLst =[]\n",
    "    mse = np.zeros(numFld)\n",
    "    \n",
    "    for fld in range(0,numFld):\n",
    "        Xtrn, Ytrn  = cvldTrnMkr(fldClm, numFld, fld+1, genericFile)\n",
    "        Xtst, Ytst = cvldTstMkr(fldClm, numFld, fld+1, genericFile)\n",
    "\n",
    "        X_m_trn = nDegExpansion(Xtrn, n)\n",
    "        X_m_tst = nDegExpansion(Xtst, n)        \n",
    "\n",
    "        Wtrn = sgdTrainRidge(X_m_trn,Ytrn,stepSize, batchSize,iterations, lmda)\n",
    "        mse[fld] = errMSE(X_m_tst, Ytst, Wtrn)\n",
    "        \n",
    "        wLst.append(Wtrn)        \n",
    "        \n",
    "    return np.mean(mse), wLst\n",
    "\n",
    "def lmdaFndr(fldClm, numFld, genericFile, n, stepSize, its, batchSize, lmdaStrt, lmdaEnd, lmdDlta):\n",
    "    lmdaLst = []\n",
    "    mseLst = []\n",
    "    wLstLst =[] #will be a list of weight list from cross Over Fit Ridge\n",
    "    lmda = lmdaStrt\n",
    "    while lmda < lmdaEnd:\n",
    "        lmdaLst.append(lmda)\n",
    "        lmda += lmdDlta\n",
    "    \n",
    "    for lmda in lmdaLst:\n",
    "        print(\"Training Lamda Value\", lmda)\n",
    "        mse, WlstLst = crossOverFitRidge(fldClm, numFld, genericFile, n, stepSize, its, batchSize, lmda)\n",
    "        mseLst.append(mse)\n",
    "        \n",
    "        \n",
    "    #recording Feature Weight information\n",
    "    fldFile = genericFile + str(1) +'.csv'\n",
    "    hdrs = getFileHeader(fldFile)\n",
    "    \n",
    "    #graphing info used for debugging \n",
    "    plt.title('Regularization Values and Cross-Validation MSE') \n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Cross Validation MSE')\n",
    "    plt.plot(lmdaLst, mseLst, 'b')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#     #outputting best fit weights\n",
    "#     numClms = wLstLst[0][0].shape[0]\n",
    "#     numLmdas = len(wLstLst)\n",
    "#     numFolds = len(wLstLst[0])\n",
    "#     wMtrx = np.zeros((numRows, numClms))\n",
    "#     for i in range(numRows):\n",
    "        \n",
    "#         wMtrx[i,:]=wLst[i]\n",
    "    \n",
    "#     fldFile = genericFile + 'ClmWeights.csv'\n",
    "#     cmbndDf = pd.DataFrame(data=wMtrx, columns=hdrs)\n",
    "#     cmbndDf.to_csv(fldFile, index=False)\n",
    "        \n",
    "stepSize = 5e-6\n",
    "iterations = 60\n",
    "batchSize = 20\n",
    "\n",
    "lmdaFndr('fold', 5, foldFlsPth, 1, stepSize, iterations, batchSize, 0, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
